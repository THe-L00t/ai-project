#!/usr/bin/env python3
"""
ì ì‘í˜• í•™ìŠµ AI ì‹œìŠ¤í…œ
- ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ê²½í—˜ í•™ìŠµ
- ì˜ˆì¸¡ ì •í™•ë„ í”¼ë“œë°± ì‹œìŠ¤í…œ
- ì§€ì†ì  ëª¨ë¸ ê°œì„ 
- ëª¨ë“  ìƒí˜¸ì‘ìš©ì—ì„œ í•™ìŠµ
"""

import os
import sys
import time
import logging
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from dotenv import load_dotenv
from collections import deque
import pickle
import json

# ë¨¸ì‹ ëŸ¬ë‹
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score
from sklearn.linear_model import SGDRegressor  # ì˜¨ë¼ì¸ í•™ìŠµìš©

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
from exchange.UpbitAPI import UpbitAPI

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/adaptive_learning.log')
    ]
)
logger = logging.getLogger(__name__)

class TradingExperienceCollector:
    """íŠ¸ë ˆì´ë”© ê²½í—˜ ìˆ˜ì§‘ê¸°"""

    def __init__(self):
        self.trade_history = deque(maxlen=10000)
        self.prediction_history = deque(maxlen=5000)
        self.market_events = deque(maxlen=1000)
        self.learning_sessions = []

    def record_trade(self, coin, action, price, quantity, timestamp=None):
        """ê±°ë˜ ê¸°ë¡"""
        trade_record = {
            'coin': coin,
            'action': action,  # 'BUY', 'SELL', 'HOLD'
            'price': price,
            'quantity': quantity,
            'timestamp': timestamp or datetime.now(),
            'market_context': self._get_market_context(coin)
        }
        self.trade_history.append(trade_record)
        logger.info(f"ğŸ“ ê±°ë˜ ê¸°ë¡: {coin} {action} @ {price:,.0f}ì›")

    def record_prediction(self, coin, predicted_change, actual_change, confidence, prediction_time):
        """ì˜ˆì¸¡ ê¸°ë¡ ë° ì •í™•ë„ ì¶”ì """
        prediction_record = {
            'coin': coin,
            'predicted_change': predicted_change,
            'actual_change': actual_change,
            'confidence': confidence,
            'prediction_time': prediction_time,
            'verification_time': datetime.now(),
            'accuracy': self._calculate_prediction_accuracy(predicted_change, actual_change),
            'direction_correct': (predicted_change * actual_change) > 0
        }
        self.prediction_history.append(prediction_record)
        logger.info(f"ğŸ¯ ì˜ˆì¸¡ ê²€ì¦: {coin} ì˜ˆì¸¡ {predicted_change:+.2f}% vs ì‹¤ì œ {actual_change:+.2f}% (ì •í™•ë„: {prediction_record['accuracy']:.2f})")

    def record_market_event(self, event_type, description, impact_coins=None):
        """ì‹œì¥ ì´ë²¤íŠ¸ ê¸°ë¡"""
        event_record = {
            'event_type': event_type,  # 'NEWS', 'PRICE_SPIKE', 'VOLUME_SURGE', 'ERROR'
            'description': description,
            'impact_coins': impact_coins or [],
            'timestamp': datetime.now()
        }
        self.market_events.append(event_record)
        logger.info(f"âš¡ ì‹œì¥ ì´ë²¤íŠ¸: {event_type} - {description}")

    def _get_market_context(self, coin):
        """ê±°ë˜ ë‹¹ì‹œ ì‹œì¥ ì»¨í…ìŠ¤íŠ¸"""
        # ê°„ë‹¨í•œ ì‹œì¥ ì •ë³´ ìˆ˜ì§‘
        try:
            from news_sentiment_ai import NewsSentimentAI
            # í˜„ì¬ ê°ì • ì ìˆ˜, ë³¼ë¥¨ ë“± ìˆ˜ì§‘
            return {
                'timestamp': datetime.now(),
                'volatility': 'medium',  # ì‹¤ì œë¡œëŠ” ê³„ì‚°
                'volume_trend': 'normal'
            }
        except:
            return {'timestamp': datetime.now()}

    def _calculate_prediction_accuracy(self, predicted, actual):
        """ì˜ˆì¸¡ ì •í™•ë„ ê³„ì‚°"""
        if actual == 0:
            return 0.5  # ì¤‘ë¦½

        # ë°©í–¥ ì •í™•ë„ + í¬ê¸° ì •í™•ë„
        direction_score = 1.0 if (predicted * actual) > 0 else 0.0
        magnitude_error = abs(predicted - actual) / (abs(actual) + 0.1)
        magnitude_score = max(0, 1 - magnitude_error)

        return (direction_score * 0.7) + (magnitude_score * 0.3)

class AdaptiveLearningEngine:
    """ì ì‘í˜• í•™ìŠµ ì—”ì§„"""

    def __init__(self):
        load_dotenv()

        self.upbit = UpbitAPI()
        self.experience_collector = TradingExperienceCollector()

        # ì˜¨ë¼ì¸ í•™ìŠµ ëª¨ë¸ë“¤
        self.online_models = {}
        self.online_scalers = {}

        # ì„±ëŠ¥ ì¶”ì 
        self.model_performance = {}
        self.learning_rate = 0.01

        # í•™ìŠµ ë°ì´í„° ë²„í¼
        self.learning_buffer = deque(maxlen=1000)

        logger.info("ğŸ§  ì ì‘í˜• í•™ìŠµ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")

    def initialize_online_models(self, coins=['BTC', 'ETH', 'ADA', 'DOT']):
        """ì˜¨ë¼ì¸ í•™ìŠµ ëª¨ë¸ ì´ˆê¸°í™”"""
        for coin in coins:
            # SGD ê¸°ë°˜ ì˜¨ë¼ì¸ í•™ìŠµ ëª¨ë¸
            self.online_models[coin] = SGDRegressor(
                learning_rate='adaptive',
                eta0=self.learning_rate,
                random_state=42
            )
            self.online_scalers[coin] = StandardScaler()
            self.model_performance[coin] = {
                'predictions': 0,
                'correct_directions': 0,
                'avg_accuracy': 0.5,
                'last_update': datetime.now()
            }

        logger.info(f"ğŸ¯ {len(coins)}ê°œ ì½”ì¸ ì˜¨ë¼ì¸ í•™ìŠµ ëª¨ë¸ ì´ˆê¸°í™”")

    def collect_real_time_features(self, coin):
        """ì‹¤ì‹œê°„ íŠ¹ì„± ìˆ˜ì§‘"""
        features = []

        try:
            # 1. ê°€ê²© ë°ì´í„°
            ticker = self.upbit.GetTicker([f'KRW-{coin}'])
            if ticker:
                price_data = ticker[0]
                features.extend([
                    float(price_data.change_rate),
                    float(price_data.acc_trade_volume_24h),
                    float(price_data.trade_price) / 100000,  # ì •ê·œí™”
                    float(price_data.high_price - price_data.low_price) / price_data.trade_price  # ë³€ë™ì„±
                ])
            else:
                features.extend([0.0] * 4)

            # 2. ìµœê·¼ ê±°ë˜ íˆìŠ¤í† ë¦¬ íŠ¹ì„±
            recent_trades = [t for t in self.experience_collector.trade_history
                           if t['coin'] == coin and
                           (datetime.now() - t['timestamp']).total_seconds() < 3600]

            if recent_trades:
                buy_count = sum(1 for t in recent_trades if t['action'] == 'BUY')
                sell_count = sum(1 for t in recent_trades if t['action'] == 'SELL')
                features.extend([
                    len(recent_trades),
                    buy_count - sell_count,  # ìˆœ ë§¤ìˆ˜/ë§¤ë„
                    buy_count / (len(recent_trades) + 0.1)  # ë§¤ìˆ˜ ë¹„ìœ¨
                ])
            else:
                features.extend([0.0] * 3)

            # 3. ì˜ˆì¸¡ ì„±ëŠ¥ ë©”íƒ€ íŠ¹ì„±
            performance = self.model_performance.get(coin, {})
            features.extend([
                performance.get('avg_accuracy', 0.5),
                performance.get('correct_directions', 0) / max(performance.get('predictions', 1), 1)
            ])

            return np.array(features)

        except Exception as e:
            logger.error(f"íŠ¹ì„± ìˆ˜ì§‘ ì‹¤íŒ¨ ({coin}): {e}")
            return np.zeros(9)

    def learn_from_trade_outcome(self, coin, trade_action, entry_price, exit_price, duration_minutes):
        """ê±°ë˜ ê²°ê³¼ë¡œë¶€í„° í•™ìŠµ"""
        try:
            # ê±°ë˜ ì„±ê³¼ ê³„ì‚°
            if trade_action == 'BUY':
                return_pct = (exit_price - entry_price) / entry_price * 100
            else:
                return_pct = (entry_price - exit_price) / entry_price * 100

            # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
            features = self.collect_real_time_features(coin)

            # ì˜¨ë¼ì¸ í•™ìŠµ
            if coin in self.online_models and len(features) > 0:
                # ìŠ¤ì¼€ì¼ëŸ¬ ì—…ë°ì´íŠ¸
                features_scaled = self.online_scalers[coin].fit_transform(features.reshape(1, -1))

                # ëª¨ë¸ ë¶€ë¶„ í•™ìŠµ
                self.online_models[coin].partial_fit(features_scaled, [return_pct])

                logger.info(f"ğŸ’¡ {coin} ê±°ë˜ ê²°ê³¼ í•™ìŠµ: {return_pct:+.2f}% ìˆ˜ìµ")

                # í•™ìŠµ ë²„í¼ì— ì¶”ê°€
                self.learning_buffer.append({
                    'coin': coin,
                    'features': features,
                    'target': return_pct,
                    'timestamp': datetime.now(),
                    'trade_type': 'outcome'
                })

        except Exception as e:
            logger.error(f"ê±°ë˜ ê²°ê³¼ í•™ìŠµ ì‹¤íŒ¨ ({coin}): {e}")

    def learn_from_prediction_feedback(self, coin, predicted_change, actual_change, prediction_confidence):
        """ì˜ˆì¸¡ í”¼ë“œë°±ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        try:
            # ì˜ˆì¸¡ ì •í™•ë„ ê¸°ë¡
            self.experience_collector.record_prediction(
                coin, predicted_change, actual_change, prediction_confidence, datetime.now()
            )

            # ì„±ëŠ¥ ì—…ë°ì´íŠ¸
            if coin in self.model_performance:
                perf = self.model_performance[coin]
                perf['predictions'] += 1

                if (predicted_change * actual_change) > 0:
                    perf['correct_directions'] += 1

                # ì´ë™ í‰ê· ìœ¼ë¡œ í‰ê·  ì •í™•ë„ ì—…ë°ì´íŠ¸
                accuracy = self.experience_collector._calculate_prediction_accuracy(predicted_change, actual_change)
                perf['avg_accuracy'] = (perf['avg_accuracy'] * 0.9) + (accuracy * 0.1)
                perf['last_update'] = datetime.now()

            # ì˜¤ì°¨ê°€ í° ê²½ìš° ì¶”ê°€ í•™ìŠµ
            error = abs(predicted_change - actual_change)
            if error > 2.0:  # 2% ì´ìƒ ì˜¤ì°¨
                features = self.collect_real_time_features(coin)

                if coin in self.online_models and len(features) > 0:
                    features_scaled = self.online_scalers[coin].transform(features.reshape(1, -1))

                    # ì˜¤ì°¨ì— ë¹„ë¡€í•œ ê°€ì¤‘ í•™ìŠµ
                    weight = min(error / 5.0, 2.0)
                    for _ in range(int(weight)):
                        self.online_models[coin].partial_fit(features_scaled, [actual_change])

                    logger.info(f"ğŸ”„ {coin} ì˜ˆì¸¡ ì˜¤ì°¨ êµì • í•™ìŠµ: {error:.2f}% ì˜¤ì°¨")

        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ í”¼ë“œë°± í•™ìŠµ ì‹¤íŒ¨ ({coin}): {e}")

    def learn_from_market_patterns(self):
        """ì‹œì¥ íŒ¨í„´ í•™ìŠµ"""
        try:
            # ìµœê·¼ ì‹œì¥ ì´ë²¤íŠ¸ ë¶„ì„
            recent_events = [e for e in self.experience_collector.market_events
                           if (datetime.now() - e['timestamp']).total_seconds() < 7200]  # 2ì‹œê°„

            if len(recent_events) < 2:
                return

            # íŒ¨í„´ ì¸ì‹ ë° í•™ìŠµ
            for coin in self.online_models.keys():
                features = self.collect_real_time_features(coin)

                # í˜„ì¬ ê°€ê²© ë³€í™” ê³„ì‚°
                ticker = self.upbit.GetTicker([f'KRW-{coin}'])
                if ticker:
                    current_change = ticker[0].change_rate * 100

                    # íŒ¨í„´ ê¸°ë°˜ í•™ìŠµ ë°ì´í„° ì¶”ê°€
                    self.learning_buffer.append({
                        'coin': coin,
                        'features': features,
                        'target': current_change,
                        'timestamp': datetime.now(),
                        'trade_type': 'pattern',
                        'market_events': [e['event_type'] for e in recent_events]
                    })

            logger.info(f"ğŸ“Š ì‹œì¥ íŒ¨í„´ í•™ìŠµ: {len(recent_events)}ê°œ ì´ë²¤íŠ¸ ë¶„ì„")

        except Exception as e:
            logger.error(f"ì‹œì¥ íŒ¨í„´ í•™ìŠµ ì‹¤íŒ¨: {e}")

    def continuous_learning_cycle(self):
        """ì§€ì†ì  í•™ìŠµ ì‚¬ì´í´"""
        logger.info("ğŸ”„ ì§€ì†ì  í•™ìŠµ ì‚¬ì´í´ ì‹œì‘")

        try:
            # 1. í•™ìŠµ ë²„í¼ ë°ì´í„°ë¡œ ë°°ì¹˜ í•™ìŠµ
            if len(self.learning_buffer) > 50:
                self._batch_learning_from_buffer()

            # 2. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ì¡°ì •
            self._evaluate_and_adjust_models()

            # 3. ì‹œì¥ íŒ¨í„´ í•™ìŠµ
            self.learn_from_market_patterns()

            # 4. í•™ìŠµ ìƒíƒœ ë¦¬í¬íŠ¸
            self._report_learning_status()

        except Exception as e:
            logger.error(f"ì§€ì†ì  í•™ìŠµ ì‹¤íŒ¨: {e}")

    def _batch_learning_from_buffer(self):
        """í•™ìŠµ ë²„í¼ ë°ì´í„°ë¡œ ë°°ì¹˜ í•™ìŠµ"""
        try:
            coin_data = {}
            for record in list(self.learning_buffer):
                coin = record['coin']
                if coin not in coin_data:
                    coin_data[coin] = {'features': [], 'targets': []}

                coin_data[coin]['features'].append(record['features'])
                coin_data[coin]['targets'].append(record['target'])

            # ì½”ì¸ë³„ ë°°ì¹˜ í•™ìŠµ
            for coin, data in coin_data.items():
                if coin in self.online_models and len(data['features']) > 10:
                    X = np.array(data['features'])
                    y = np.array(data['targets'])

                    # ìŠ¤ì¼€ì¼ë§
                    X_scaled = self.online_scalers[coin].fit_transform(X)

                    # ë°°ì¹˜ í•™ìŠµ
                    self.online_models[coin].partial_fit(X_scaled, y)

                    logger.info(f"ğŸ“š {coin} ë°°ì¹˜ í•™ìŠµ: {len(data['features'])}ê°œ ìƒ˜í”Œ")

            # ë²„í¼ ì •ë¦¬
            self.learning_buffer.clear()

        except Exception as e:
            logger.error(f"ë°°ì¹˜ í•™ìŠµ ì‹¤íŒ¨: {e}")

    def _evaluate_and_adjust_models(self):
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ì¡°ì •"""
        for coin, performance in self.model_performance.items():
            try:
                accuracy = performance['avg_accuracy']
                correct_ratio = performance['correct_directions'] / max(performance['predictions'], 1)

                # ì„±ëŠ¥ì´ ë‚®ìœ¼ë©´ í•™ìŠµë¥  ì¡°ì •
                if accuracy < 0.4 or correct_ratio < 0.45:
                    if coin in self.online_models:
                        self.online_models[coin].eta0 *= 1.1  # í•™ìŠµë¥  ì¦ê°€
                        logger.warning(f"ğŸ“ˆ {coin} í•™ìŠµë¥  ì¦ê°€: ì„±ëŠ¥ ê°œì„  í•„ìš” (ì •í™•ë„: {accuracy:.2f})")

                elif accuracy > 0.7 and correct_ratio > 0.65:
                    if coin in self.online_models:
                        self.online_models[coin].eta0 *= 0.9  # í•™ìŠµë¥  ê°ì†Œ
                        logger.info(f"ğŸ“‰ {coin} í•™ìŠµë¥  ì•ˆì •í™”: ì¢‹ì€ ì„±ëŠ¥ ìœ ì§€ (ì •í™•ë„: {accuracy:.2f})")

            except Exception as e:
                logger.error(f"{coin} ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {e}")

    def _report_learning_status(self):
        """í•™ìŠµ ìƒíƒœ ë¦¬í¬íŠ¸"""
        logger.info("\nğŸ“ í•™ìŠµ ìƒíƒœ ë¦¬í¬íŠ¸:")
        for coin, performance in self.model_performance.items():
            predictions = performance['predictions']
            correct = performance['correct_directions']
            accuracy = performance['avg_accuracy']

            if predictions > 0:
                logger.info(f"   {coin}: {predictions}ë²ˆ ì˜ˆì¸¡, {correct}ë²ˆ ë°©í–¥ ë§ì¶¤ ({correct/predictions:.1%}), í‰ê·  ì •í™•ë„ {accuracy:.2f}")
            else:
                logger.info(f"   {coin}: ì˜ˆì¸¡ ê¸°ë¡ ì—†ìŒ")

    def get_enhanced_prediction(self, coin):
        """ê°•í™”ëœ ì˜ˆì¸¡ (í•™ìŠµ ê²½í—˜ ë°˜ì˜)"""
        try:
            if coin not in self.online_models:
                return None

            features = self.collect_real_time_features(coin)
            if len(features) == 0:
                return None

            # ì˜¨ë¼ì¸ ëª¨ë¸ ì˜ˆì¸¡
            features_scaled = self.online_scalers[coin].transform(features.reshape(1, -1))
            prediction = self.online_models[coin].predict(features_scaled)[0]

            # ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜ ì‹ ë¢°ë„ ì¡°ì •
            performance = self.model_performance[coin]
            base_confidence = performance['avg_accuracy']

            # ìµœê·¼ ì„±ê³¼ ê¸°ë°˜ ì‹ ë¢°ë„ ë³´ì •
            recent_predictions = [p for p in self.experience_collector.prediction_history
                                if p['coin'] == coin and
                                (datetime.now() - p['verification_time']).total_seconds() < 1800]  # 30ë¶„

            if recent_predictions:
                recent_accuracy = np.mean([p['accuracy'] for p in recent_predictions])
                confidence = (base_confidence * 0.7) + (recent_accuracy * 0.3)
            else:
                confidence = base_confidence

            return {
                'coin': coin,
                'predicted_change_pct': prediction,
                'confidence': confidence,
                'model_predictions': performance['predictions'],
                'model_accuracy': performance['avg_accuracy'],
                'timestamp': datetime.now()
            }

        except Exception as e:
            logger.error(f"{coin} ê°•í™” ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return None

    def save_learning_state(self, filepath='models/adaptive_learning_state.pkl'):
        """í•™ìŠµ ìƒíƒœ ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(filepath), exist_ok=True)

            state_data = {
                'online_models': self.online_models,
                'online_scalers': self.online_scalers,
                'model_performance': self.model_performance,
                'trade_history': list(self.experience_collector.trade_history)[-500:],  # ìµœê·¼ 500ê°œ
                'prediction_history': list(self.experience_collector.prediction_history)[-200:],
                'market_events': list(self.experience_collector.market_events)[-100:],
                'learning_rate': self.learning_rate,
                'timestamp': datetime.now()
            }

            with open(filepath, 'wb') as f:
                pickle.dump(state_data, f)

            logger.info(f"ğŸ’¾ í•™ìŠµ ìƒíƒœ ì €ì¥ ì™„ë£Œ: {filepath}")

        except Exception as e:
            logger.error(f"í•™ìŠµ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}")

    def load_learning_state(self, filepath='models/adaptive_learning_state.pkl'):
        """í•™ìŠµ ìƒíƒœ ë¡œë“œ"""
        try:
            if os.path.exists(filepath):
                with open(filepath, 'rb') as f:
                    state_data = pickle.load(f)

                self.online_models = state_data.get('online_models', {})
                self.online_scalers = state_data.get('online_scalers', {})
                self.model_performance = state_data.get('model_performance', {})
                self.learning_rate = state_data.get('learning_rate', 0.01)

                # íˆìŠ¤í† ë¦¬ ë³µì›
                if 'trade_history' in state_data:
                    self.experience_collector.trade_history.extend(state_data['trade_history'])
                if 'prediction_history' in state_data:
                    self.experience_collector.prediction_history.extend(state_data['prediction_history'])
                if 'market_events' in state_data:
                    self.experience_collector.market_events.extend(state_data['market_events'])

                logger.info(f"ğŸ“‚ í•™ìŠµ ìƒíƒœ ë¡œë“œ ì™„ë£Œ: {filepath}")
                return True
            else:
                logger.info("ì €ì¥ëœ í•™ìŠµ ìƒíƒœê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
                return False

        except Exception as e:
            logger.error(f"í•™ìŠµ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

def main():
    """í…ŒìŠ¤íŠ¸ ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ§  ì ì‘í˜• í•™ìŠµ AI í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    try:
        ai = AdaptiveLearningEngine()
        ai.load_learning_state()
        ai.initialize_online_models()

        # í…ŒìŠ¤íŠ¸ í•™ìŠµ ì‚¬ì´í´
        for i in range(5):
            logger.info(f"\nğŸ”„ í•™ìŠµ ì‚¬ì´í´ #{i+1}")
            ai.continuous_learning_cycle()

            # ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
            for coin in ['BTC', 'ETH']:
                prediction = ai.get_enhanced_prediction(coin)
                if prediction:
                    logger.info(f"ğŸ”® {coin} ì˜ˆì¸¡: {prediction['predicted_change_pct']:+.2f}% (ì‹ ë¢°ë„: {prediction['confidence']:.2f})")

            time.sleep(10)  # 10ì´ˆ ëŒ€ê¸°

        ai.save_learning_state()

    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ì‚¬ìš©ì ì¤‘ì§€")
    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main()